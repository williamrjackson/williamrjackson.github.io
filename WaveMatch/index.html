<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <title>Unity Web Player | WavesWall</title>
  </head>
  <body style="text-align: center; padding: 0; border: 0; margin: 0; position: relative;">
    <div id="audio-overlay" style="position: fixed; top: 0; left: 0; width: 100%; height: 100%; background: rgba(0, 0, 0, 0.7); display: flex; align-items: center; justify-content: center; z-index: 1000;">
      <button id="start-button" style="padding: 20px 40px; font-size: 24px; background: #4CAF50; color: white; border: none; border-radius: 8px; cursor: pointer; font-weight: bold; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.3);">
        ðŸ”Š Start Activity (Audio Enabled)
      </button>
    </div>
    <canvas id="unity-canvas" width=960 height=540 tabindex="-1" style="width: 960px; height: 540px; background: #231F20"></canvas>
    <script>
      // Intercept AudioContext creation to capture Unity's audio context
      window.unityAudioContexts = [];
      const OriginalAudioContext = window.AudioContext || window.webkitAudioContext;
      
      if (OriginalAudioContext) {
        const AudioContextProxy = function() {
          const ctx = new OriginalAudioContext(...arguments);
          window.unityAudioContexts.push(ctx);
          console.log('AudioContext created, state:', ctx.state);
          return ctx;
        };
        AudioContextProxy.prototype = OriginalAudioContext.prototype;
        window.AudioContext = AudioContextProxy;
        if (window.webkitAudioContext) {
          window.webkitAudioContext = AudioContextProxy;
        }
      }
    </script>
    <script src="Build/WaveMatch.loader.js"></script>
    <script>
      if (/iPhone|iPad|iPod|Android/i.test(navigator.userAgent)) {
        // Mobile device style: fill the whole browser client area with the game canvas:
        var meta = document.createElement('meta');
        meta.name = 'viewport';
        meta.content = 'width=device-width, height=device-height, initial-scale=1.0, user-scalable=no, shrink-to-fit=yes';
        document.getElementsByTagName('head')[0].appendChild(meta);

        var canvas = document.querySelector("#unity-canvas");
        canvas.style.width = "100%";
        canvas.style.height = "100%";
        canvas.style.position = "fixed";

        document.body.style.textAlign = "left";

      }

      createUnityInstance(document.querySelector("#unity-canvas"), {
        arguments: [],
        dataUrl: "Build/WaveMatch.data",
        frameworkUrl: "Build/WaveMatch.framework.js",
        codeUrl: "Build/WaveMatch.wasm",
        streamingAssetsUrl: "StreamingAssets",
        companyName: "Museum of Science",
        productName: "WavesWall",
        productVersion: "1.0",
        // matchWebGLToCanvasSize: false, // Uncomment this to separately control WebGL canvas render size and DOM element size.
        // devicePixelRatio: 1, // Uncomment this to override low DPI rendering on high DPI displays.
      }).then((unityInstance) => {
        // Handle audio context resumption on Start button
        const startButton = document.getElementById('start-button');
        const audioOverlay = document.getElementById('audio-overlay');
        const canvas = document.querySelector("#unity-canvas");
        
        startButton.addEventListener('click', () => {
          // Focus and simulate multiple interaction types on the canvas
          canvas.focus();
          
          // Dispatch click event
          canvas.dispatchEvent(new MouseEvent('mousedown', { bubbles: true, cancelable: true, view: window }));
          canvas.dispatchEvent(new MouseEvent('mouseup', { bubbles: true, cancelable: true, view: window }));
          canvas.dispatchEvent(new MouseEvent('click', { bubbles: true, cancelable: true, view: window }));
          
          // Dispatch touch events for mobile compatibility
          canvas.dispatchEvent(new TouchEvent('touchstart', { bubbles: true, cancelable: true, view: window }));
          canvas.dispatchEvent(new TouchEvent('touchend', { bubbles: true, cancelable: true, view: window }));
          
          // Resume all captured AudioContext instances
          console.log('Found', window.unityAudioContexts.length, 'AudioContext(s)');
          window.unityAudioContexts.forEach((ctx, index) => {
            console.log('AudioContext', index, 'state:', ctx.state);
            if (ctx.state === 'suspended') {
              ctx.resume().then(() => {
                console.log('AudioContext', index, 'resumed successfully');
              }).catch(err => {
                console.error('Failed to resume AudioContext', index, err);
              });
            }
          });
          
          // Also check for WEBAudio and other common Unity audio objects
          setTimeout(() => {
            if (typeof WEBAudio !== 'undefined' && WEBAudio.audioContext) {
              console.log('Found WEBAudio.audioContext, state:', WEBAudio.audioContext.state);
              if (WEBAudio.audioContext.state === 'suspended') {
                WEBAudio.audioContext.resume();
              }
            }
            if (typeof Module !== 'undefined' && Module.SDL2 && Module.SDL2.audioContext) {
              console.log('Found Module.SDL2.audioContext, state:', Module.SDL2.audioContext.state);
              if (Module.SDL2.audioContext.state === 'suspended') {
                Module.SDL2.audioContext.resume();
              }
            }
          }, 500);
          
          console.log('Audio initialization triggered');
          
          // Hide the overlay and button
          audioOverlay.style.display = 'none';
        });
      }).catch((message) => {
        alert(message);
      });
    </script>
  </body>
</html>
